---
title: Thinking in Bets
category: books
permalink: /:categories/:title/
author:  Annie Duke
layout: bookpost
tags:
- booknotes
---

>  Game theory was succinctly defined by economist Roger Myerson (one of the game-theory Nobel laureates) as “the study of mathematical models of conflict and cooperation between intelligent rational decision-makers.”

>  Trouble follows when we treat life decisions as if they were chess decisions.

>  Poker, in contrast, is a game of incomplete information. It is a game of decision-making under conditions of uncertainty over time. (Not coincidentally, that is close to the definition of game theory.)

>  The quality of our lives is the sum of decision quality plus luck.

>  What did it mean to be a “movie star”? He quoted an actor who explained the type of characters he wanted to play: “I don’t want to be the man who learns. I want to be the man who knows.”

>  failure but a necessary step toward enlightenment. He backs this up with a great quote from physicist James Clerk Maxwell: “Thoroughly conscious ignorance is the prelude to every real advance in science.” I would add that this is a prelude to every great decision that has ever been made.

>  What makes a decision great is not that it has a great outcome. A great decision is the result of a good process, and that process must include an attempt to accurately represent our own state of knowledge. That state of knowledge, in turn, is some variation of “I’m not sure.”

>  Decisions are bets on the future, and they aren’t “right” or “wrong” based on whether they turn out well on any particular iteration.

>  In most of our decisions, we are not betting against another person. Rather, we are betting against all the future versions of ourselves that we are not choosing.

>  “This pattern of polarization . . . does not abate among high-Numeracy subjects. Indeed, it increases.”

>  “Wanna bet?” triggers us to engage in that third step that we only sometimes get to. Being asked if we are willing to bet money on it makes it much more likely that we will examine our information in a less biased way, be more honest with ourselves about how sure we are of our beliefs, and be more open to updating and calibrating our beliefs.

>  As novelist and philosopher Aldous Huxley recognized, “Experience is not what happens to a man; it is what a man does with what happens to him.”

>  Chalk up an outcome to skill, and we take credit for the result. Chalk up an outcome to luck, and it wasn’t in our control.

>  You could ingest sugar-laden SnackWell’s by the box, because sugar wasn’t the enemy. Fat was the enemy, and the packaging screamed “LOW FAT!” Of course, we know now that obesity rose significantly during the low-fat craze.

>  Hellmuth said on camera to ESPN, “If it weren’t for luck, I’d win every one.”

>  An experienced player will choose to play only about 20% of the hands they are dealt, forfeiting the other 80% of the hands before even getting past the first round of betting.

>  By several estimates, all of these variables put together account for no more than 8% to 15% of the variance in happiness.” What accounts for most of the variance in happiness is how we’re doing comparatively.

>  Habits operate in a neurological loop consisting of three parts: the cue, the routine, and the reward.

>  American soccer great Mia Hamm said, “Many people say I’m the best women’s soccer player in the world. I don’t think so. And because of that, someday I just might be.”

>  What you don’t see are practice rituals like Phil Mickelson’s, in which he places ten balls in a circle, three feet from the hole. He has to sink all ten, and then repeat the process nine more times.

>  It’s easy to win a bet against someone who takes extreme positions.)

>  The benefits of recognizing just a few extra learning opportunities compound over time. The cumulative effect of being a little better at decision-making, like compounding interest, can have huge effects in the long run on everything that we do.

>  If you have gotten this far in this book, I’m guessing that you are choosing the red pill over the blue pill.

>  combination, the advice of these experts in group interaction adds up to a pretty good blueprint for a truthseeking charter: A focus on accuracy (over confirmation), which includes rewarding truthseeking, objectivity, and open-mindedness within the group; Accountability, for which members have advance notice; and Openness to a diversity of ideas. An agreement along these lines creates a common bond and shared fate among members, allowing the group to produce sound reasoning.

>  Talking about winning (even if we are identifying mistakes along the way to a win) is less painful than talking about losing, allowing new habits to be more easily trained. Identifying mistakes in hands I won reinforced the separation between outcomes and decision quality.

>  was much less likely to break a loss limit because I knew I was accountable to my pod. If I reached my loss limit and my inner voice said, “This game is so good that I should put up more money and keep playing,” it also reminded me I’d have to answer for the decision to a group of players I respected. Accountability made me run that conversation in my head, in which I started explaining how I was just getting unlucky and they would expose why I was likely biased in my assessment, helping me resist the urge to buy more chips.

>  Imagining how the discussion will go helps us to spot more errors on our own and catch them more quickly.

>  One of the frequent themes in On Liberty is the importance of diversity of opinion. Diversity and dissent are not only checks on fallibility, but the only means of testing the ultimate truth of an opinion: “The only way in which a human being can make some approach to knowing the whole of a subject, is by hearing what can be said about it by persons of every variety of opinion, and studying all modes in which it can be looked at by every character of mind. No wise man ever acquired his wisdom in any mode but this; nor is it in the nature of human intellect to become wise in any other manner.”

>  After September 11, the CIA created “red teams” that, according to Georgetown law professor Neal Katyal in a New York Times op-ed, “are dedicated to arguing against the intelligence community’s conventional wisdom and spotting flaws in logic and analysis.”

>  Dissent channels and red teams are a beautiful implementation of Mill’s bedrock principle that we can’t know the truth of a matter without hearing the other side.

>  Cass Sunstein, now a Harvard law professor, conducted a massive study with colleagues when he was on the faculty at the University of Chicago Law School, on ideological diversity in federal judicial panels. Sunstein recognized at the outset that the U.S. Courts of Appeals are “an extraordinary and longstanding natural experiment” in diversity.

>  The study, encompassing over 6,000 federal appeals and nearly 20,000 individual votes, found, not surprisingly, that judicial voting generally followed political lines.

>  When there was political diversity on the panels, the researchers found several areas where that diversity improved the panel’s work.

>  Justice Thomas, from 1986 to the time the article was written, was 84-for-84 in hiring clerks who had worked for Republican-appointed judges. Not surprisingly, according to data compiled from the Journal of Law, Economics, and Organization, he is the justice furthest from the ideological center of the court, much further right than the most liberal-leaning justice (Sotomayor) is left.

>  First, the Heterodox Academy effort shows that there is a natural drift toward homogeneity and confirmatory thought. We all experience this gravitation toward people who think like we do.

>  Second, groups with diverse viewpoints are the best protection against confirmatory thought. Peer review, the gold standard that epitomizes the open-mindedness and hypothesis testing of the scientific method, “offers much less protection against error when the community of peers is politically homogeneous.”

>  Accuracy, accountability, and diversity wrapped into a group’s charter all contribute to better decision-making, especially if the group promotes thinking in bets.

>  The founders of Heterodox Academy, in the BBS paper, specifically recognized Merton’s 1942 and 1973 papers, in which he established norms for the scientific community known by the acronym CUDOS: “An ideologically balanced science that routinely resorted to adversarial collaborations to resolve empirical disputes would bear a striking resemblance to Robert Merton’s ideal-type model of a self-correcting epistemic community, one organized around the norms of CUDOS.”

>  Per the BBS paper, CUDOS stands for Communism (data belong to the group), Universalism (apply uniform standards to claims and evidence, regardless of where they came from), Disinterestedness (vigilance against potential conflicts that can influence the group’s evaluation), and Organized Skepticism (discussion among the group to encourage engagement and dissent).

>  In 1942, Merton wrote about the normative structure of science. He tinkered with the paper over the next thirty-one years, publishing the final version as part of a book in 1973. This twelve-page paper is an excellent manual for developing rules of engagement for any truthseeking group. I recognized its application to my poker group and professional and workplace groups I’ve encountered in speaking and consulting.

>  We have all experienced situations where we get two accounts of the same event, but the versions are dramatically different because they are informed by different facts and perspectives. This is known as the Rashomon Effect, named for the 1950 cinematic classic Rashomon, directed by Akira Kurosawa.

>  The well-known advice “don’t shoot the messenger” is actually good shorthand for the reasons why we want to protect and encourage dissenting ideas. Plutarch’s Life of Lucullus provided an early, literal example: the king of Armenia got advance notice that Lucullus’s troops were approaching. He killed the messenger for delivering that message and, henceforth, messengers stopped reporting such intelligence.

>  Simply put, the group is less likely to succumb to ideological conflicts of interest when they don’t know what the interest is. That’s MacCoun and Perlmutter’s point.

>  Just as the CIA has red teams and the State Department has its Dissent Channel, we can incorporate dissent into our business and personal lives. We can create a pod whose job (literally, in business, or figuratively, in our personal life) is to present the other side, to argue why a strategy might be ill-advised, why a prediction might be off, or why an idea might be ill informed.

>  When we lead with assent, our listeners will be more open to any dissent that might follow.

>  The important thing is to try to find areas of agreement to maintain the spirit of partnership in seeking the truth. In expressing potentially contradictory or dissenting information, our language ideally minimizes the element of disagreement.

>  Flipping that on its head, it doesn’t have to be offensive to ask, “Do you want to just let it all out, or are you thinking of what to do about it next?”

>  Rather than rehashing what has already happened, try instead to engage about what the person might do so that things will turn out better going forward.

>  That leads to the final decision strategy of this book: ways to use time-travel techniques for better decision-making. By recruiting past and future versions of yourself, you can become your own buddy.

>  This tendency we all have to favor our present-self at the expense of our future-self is called temporal discounting.* We are willing to take an irrationally large discount to get a reward now instead of waiting for a bigger reward later.

>  I knew I would be better off if I played just six to eight hours per session. When I reached that point in a session and considered continuing past that time limit, I could use a 10-10-10-like strategy to recruit my past-and future-self: How have I felt when I kept playing in the past?

>  Our problem is that we’re ticker watchers of our own lives. Happiness (however we individually define it) is not best measured by looking at the ticker, zooming in and magnifying moment-by-moment or day-by-day movements. We would be better off thinking about our happiness as a long-term stock holding.

>  The scoreboard, like a stock ticker, reflects the most recent changes, creating a risk that players get caught up in ticker watching, responding emotionally and disproportionately to momentary fluctuations. Poker players think about this problem a lot.

>  The concept of tilt comes from traditional pinball machines. To keep players from damaging the machines by lifting them to alter the course of the ball, the manufacturers placed sensors inside that disabled the machine if it was violently jostled. The flippers stopped working, the lights went off, and the word “tilt” flashed at numerous places on the layout. The origin of tilt in pinball is apt because what’s going on in our brain in moments of tilt is like a shaken pinball machine. When the emotional center of the brain starts pinging, the limbic system (specifically the amygdala) shuts down the prefrontal cortex. We light up . . . then we shut down our cognitive control center.

>  This action—past-us preventing present-us from doing something stupid—has become known as a Ulysses contract.

>  Figure out the possibilities, then take a stab at the probabilities. To start, we imagine the range of potential futures. This is also known as scenario planning.

>  In early February 2017, he described the merits of scenario planning: “When faced with highly uncertain conditions, military units and major corporations sometimes use an exercise called scenario planning. The idea is to consider a broad range of possibilities for how the future might unfold to help guide long-term planning and preparation.”

>  Being able to respond to the changing future is a good thing; being surprised by the changing future is not. Scenario planning makes us nimbler because we’ve considered and are prepared for a wider variety of possible futures.

>  Finally, by mapping out the potential futures and probabilities, we are less likely to fall prey to resulting or hindsight bias, in which we gloss over the futures that did not occur and behave as if the one that did occur must have been inevitable, because we have memorialized all the possible futures that could have happened.

>  Overall, their post-outcome reviews focused on understanding what worked, what didn’t work, what was luck, and how to do better, improving both their probability estimates and the quality of their grant applications.

>  Imagining the future recruits the same brain pathways as remembering the past. And it turns out that remembering the future is a better way to plan for it. From the vantage point of the present, it’s hard to see past the next step.

>  The world changes too fast to assume that approach is generally valid. Samuel Arbesman’s The Half-Life of Facts makes a book-length case for the hazards of assuming the future is going to be like the present.

>  By working backward from the goal, we plan our decision tree in more depth, because we start at the end.

>  Backcasting reveals the positive space. Premortems reveal the negative space. Backcasting is the cheerleader; a premortem is the heckler in the audience.

>  Despite the popular wisdom that we achieve success through positive visualization, it turns out that incorporating negative visualization makes us more likely to achieve our goals.

>  Gabriele Oettingen, professor of psychology at NYU and author of Rethinking Positive Thinking: Inside the New Science of Motivation, has conducted over twenty years of research, consistently finding that people who imagine obstacles in the way of reaching their goals are more likely to achieve success, a process she has called “mental contrasting.”

>  Even the smallest of twigs, the most improbable of futures—like the 2%–3% chance Russell Wilson would throw that interception—expands when it becomes part of the mighty trunk. That 2%–3%, in hindsight, becomes 100%, and all the other branches, no matter how thick they were, disappear from view. That’s hindsight bias, an enemy of probabilistic thinking.

